{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yavDST0qyMg_",
        "dIBYIC05yRFR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9195664e946541ce835a76b41e03749f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bab7c71287074a56905964c2d22d4fd0",
              "IPY_MODEL_7f9565db30ce4d44b5d9c7cdea207ba7",
              "IPY_MODEL_7e51caef30b94a7ebee48ea8b514a016"
            ],
            "layout": "IPY_MODEL_ea320908140a4c938536d074dfed15c5"
          }
        },
        "bab7c71287074a56905964c2d22d4fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_963003d0dc204d129b4c4bdbabde20ac",
            "placeholder": "​",
            "style": "IPY_MODEL_68cf58e22c144f1f894de6bd11c92763",
            "value": "Downloading: 100%"
          }
        },
        "7f9565db30ce4d44b5d9c7cdea207ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90228885f4004f8c99e4c8980d149a39",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc237ca4cddf4d2cb612b8b2fd645cae",
            "value": 385
          }
        },
        "7e51caef30b94a7ebee48ea8b514a016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a97136d016c24137804db90a74514ca4",
            "placeholder": "​",
            "style": "IPY_MODEL_161e45f53dec437890081f10f4e8cef1",
            "value": " 385/385 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "ea320908140a4c938536d074dfed15c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "963003d0dc204d129b4c4bdbabde20ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cf58e22c144f1f894de6bd11c92763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90228885f4004f8c99e4c8980d149a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc237ca4cddf4d2cb612b8b2fd645cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a97136d016c24137804db90a74514ca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161e45f53dec437890081f10f4e8cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96855ebb653c470bb56df72591c1bdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5725fe46998b441cb9ba2ed372a975d2",
              "IPY_MODEL_059df2203dd74cdea1e56a2a7495f417",
              "IPY_MODEL_c26fc4ce60cb4fa686b5cb803b001431"
            ],
            "layout": "IPY_MODEL_241daa8666be4c9e8998ba1880be69a5"
          }
        },
        "5725fe46998b441cb9ba2ed372a975d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d1950d598244d8b8c408fb026822511",
            "placeholder": "​",
            "style": "IPY_MODEL_224b980d21b74348ba8f6fe2ba5e9996",
            "value": "Downloading: 100%"
          }
        },
        "059df2203dd74cdea1e56a2a7495f417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e3bc79398a84c69ac3d26562b324b50",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8824017a2cb40d79e3697624d4ca444",
            "value": 213450
          }
        },
        "c26fc4ce60cb4fa686b5cb803b001431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fbed5ac3804608a9ade331ba6bf3bf",
            "placeholder": "​",
            "style": "IPY_MODEL_6b7846406af14f41aebd23b3e5e9c85b",
            "value": " 213k/213k [00:00&lt;00:00, 309kB/s]"
          }
        },
        "241daa8666be4c9e8998ba1880be69a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1950d598244d8b8c408fb026822511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224b980d21b74348ba8f6fe2ba5e9996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e3bc79398a84c69ac3d26562b324b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8824017a2cb40d79e3697624d4ca444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76fbed5ac3804608a9ade331ba6bf3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7846406af14f41aebd23b3e5e9c85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2714cb17b48b4599b1518eb1c97aaf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4890895c72964a07965d94d3745acb3d",
              "IPY_MODEL_11bb15c327a64e9a919b043019641b69",
              "IPY_MODEL_1c37cc7201d54a348c988db6352e878e"
            ],
            "layout": "IPY_MODEL_9b3d0ee82ca548c9908a02be8d4baf97"
          }
        },
        "4890895c72964a07965d94d3745acb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1555473c512a4ccf8d78445cc29ee0ed",
            "placeholder": "​",
            "style": "IPY_MODEL_56328d0cf6ee4e1688ece5b1e9f00c68",
            "value": "Downloading: 100%"
          }
        },
        "11bb15c327a64e9a919b043019641b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c015f74bdf0545f790f93f67d679e65a",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f6fae2a7fbe423594b933a98ae70104",
            "value": 435778770
          }
        },
        "1c37cc7201d54a348c988db6352e878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73041d741eb643579b8e9493874f23a0",
            "placeholder": "​",
            "style": "IPY_MODEL_9d90c5fcaa574d86bb80bb897b2cc82a",
            "value": " 436M/436M [00:25&lt;00:00, 17.6MB/s]"
          }
        },
        "9b3d0ee82ca548c9908a02be8d4baf97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1555473c512a4ccf8d78445cc29ee0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56328d0cf6ee4e1688ece5b1e9f00c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c015f74bdf0545f790f93f67d679e65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6fae2a7fbe423594b933a98ae70104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73041d741eb643579b8e9493874f23a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d90c5fcaa574d86bb80bb897b2cc82a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bagian yang masih sama dengan TP 3"
      ],
      "metadata": {
        "id": "HXeKM9qgMJAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## util.py"
      ],
      "metadata": {
        "id": "yavDST0qyMg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsnWmkQjbD8t",
        "outputId": "e2aaf8e9-eba6-4f9e-c114-71f86cb221b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbL63LHqx-Iu",
        "outputId": "875ad32e-25e5-47b7-9124-d9a3dd4e2e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "class IdMap:\n",
        "    \"\"\"\n",
        "    Ingat kembali di kuliah, bahwa secara praktis, sebuah dokumen dan\n",
        "    sebuah term akan direpresentasikan sebagai sebuah integer. Oleh\n",
        "    karena itu, kita perlu maintain mapping antara string term (atau\n",
        "    dokumen) ke integer yang bersesuaian, dan sebaliknya. Kelas IdMap ini\n",
        "    akan melakukan hal tersebut.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Mapping dari string (term atau nama dokumen) ke id disimpan dalam\n",
        "        python's dictionary; cukup efisien. Mapping sebaliknya disimpan dalam\n",
        "        python's list.\n",
        "\n",
        "        contoh:\n",
        "            str_to_id[\"halo\"] ---> 8\n",
        "            str_to_id[\"/collection/dir0/gamma.txt\"] ---> 54\n",
        "\n",
        "            id_to_str[8] ---> \"halo\"\n",
        "            id_to_str[54] ---> \"/collection/dir0/gamma.txt\"\n",
        "        \"\"\"\n",
        "        self.str_to_id = {}\n",
        "        self.id_to_str = []\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Mengembalikan banyaknya term (atau dokumen) yang disimpan di IdMap.\"\"\"\n",
        "        return len(self.id_to_str)\n",
        "\n",
        "    def __get_str(self, i):\n",
        "        \"\"\"Mengembalikan string yang terasosiasi dengan index i.\"\"\"\n",
        "        # TODO\n",
        "        return self.id_to_str[i]\n",
        "\n",
        "    def __get_id(self, s):\n",
        "        \"\"\"\n",
        "        Mengembalikan integer id i yang berkorespondensi dengan sebuah string s.\n",
        "        Jika s tidak ada pada IdMap, lalu assign sebuah integer id baru dan kembalikan\n",
        "        integer id baru tersebut.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        if s not in self.id_to_str:\n",
        "            self.id_to_str.append(s)\n",
        "            idx = self.id_to_str.index(s)\n",
        "            self.str_to_id[s] = idx\n",
        "        return self.str_to_id[s]\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        \"\"\"\n",
        "        __getitem__(...) adalah special method di Python, yang mengizinkan sebuah\n",
        "        collection class (seperti IdMap ini) mempunyai mekanisme akses atau\n",
        "        modifikasi elemen dengan syntax [..] seperti pada list dan dictionary di Python.\n",
        "\n",
        "        Silakan search informasi ini di Web search engine favorit Anda. Saya mendapatkan\n",
        "        link berikut:\n",
        "\n",
        "        https://stackoverflow.com/questions/43627405/understanding-getitem-method\n",
        "\n",
        "        Jika key adalah integer, gunakan __get_str;\n",
        "        jika key adalah string, gunakan __get_id\n",
        "        \"\"\"\n",
        "        if type(key) is int:\n",
        "            return self.__get_str(key)\n",
        "        elif type(key) is str:\n",
        "            return self.__get_id(key)\n",
        "        else:\n",
        "            raise TypeError\n",
        "\n",
        "def sorted_merge_posts_and_tfs(posts_tfs1, posts_tfs2):\n",
        "    \"\"\"\n",
        "    Menggabung (merge) dua lists of tuples (doc id, tf) dan mengembalikan\n",
        "    hasil penggabungan keduanya (TF perlu diakumulasikan untuk semua tuple\n",
        "    dengn doc id yang sama), dengan aturan berikut:\n",
        "\n",
        "    contoh: posts_tfs1 = [(1, 34), (3, 2), (4, 23)]\n",
        "            posts_tfs2 = [(1, 11), (2, 4), (4, 3 ), (6, 13)]\n",
        "\n",
        "            return   [(1, 34+11), (2, 4), (3, 2), (4, 23+3), (6, 13)]\n",
        "                   = [(1, 45), (2, 4), (3, 2), (4, 26), (6, 13)]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    list1: List[(Comparable, int)]\n",
        "    list2: List[(Comparable, int]\n",
        "        Dua buah sorted list of tuples yang akan di-merge.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[(Comparablem, int)]\n",
        "        Penggabungan yang sudah terurut\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    sorted_lst = []\n",
        "    p1, p2 = 0, 0\n",
        "    while p1 < len(posts_tfs1) and p2 < len(posts_tfs2):\n",
        "        if (posts_tfs1[p1][0] == posts_tfs2[p2][0]):\n",
        "            same_term = posts_tfs1[p1][0]\n",
        "            sum_tf = posts_tfs1[p1][1] + posts_tfs2[p2][1]\n",
        "            sorted_lst.append((same_term, sum_tf))\n",
        "            p1 += 1\n",
        "            p2 += 1\n",
        "        elif posts_tfs1[p1] < posts_tfs2[p2]:\n",
        "            sorted_lst.append(posts_tfs1[p1])\n",
        "            p1 += 1\n",
        "        else:\n",
        "            sorted_lst.append(posts_tfs2[p2])\n",
        "            p2 += 1\n",
        "    else:\n",
        "        if p1 < len(posts_tfs1):\n",
        "            sorted_lst.append(posts_tfs1[p1])\n",
        "            p1 += 1\n",
        "        elif p2 < len(posts_tfs2):\n",
        "            sorted_lst.append(posts_tfs2[p2])\n",
        "            p2 += 2\n",
        "\n",
        "    return sorted_lst\n",
        "\n",
        "def text_preprocess(string):\n",
        "    \"Mengembalikan hasil preprocess dari suatu teks string.\"\n",
        "    # Normalization\n",
        "    res = string.lower().strip()\n",
        "    res = re.sub(\"\\d\", \"\", res) # Menghilangkan angka\n",
        "    res = re.sub(\"\\s+\", \" \", res) # Menghilangkan spasi berlebih\n",
        "    res = re.sub(\"[^\\w\\s]\", \" \", res) # Menghilangkan tanda baca\n",
        "\n",
        "    words = word_tokenize(res)\n",
        "\n",
        "    stop_words = stopwords.words('english')\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    porter = PorterStemmer()\n",
        "    stemmed = [porter.stem(word) for word in filtered_words]\n",
        "\n",
        "    return stemmed\n",
        "\n",
        "def test(output, expected):\n",
        "    \"\"\" simple function for testing \"\"\"\n",
        "    return \"PASSED\" if output == expected else \"FAILED\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## compression.py"
      ],
      "metadata": {
        "id": "dIBYIC05yRFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "\n",
        "class VBEPostings:\n",
        "    \"\"\" \n",
        "    Berbeda dengan StandardPostings, dimana untuk suatu postings list,\n",
        "    yang disimpan di disk adalah sequence of integers asli dari postings\n",
        "    list tersebut apa adanya.\n",
        "\n",
        "    Pada VBEPostings, kali ini, yang disimpan adalah gap-nya, kecuali\n",
        "    posting yang pertama. Barulah setelah itu di-encode dengan Variable-Byte\n",
        "    Enconding algorithm ke bytestream.\n",
        "\n",
        "    Contoh:\n",
        "    postings list [34, 67, 89, 454] akan diubah dulu menjadi gap-based,\n",
        "    yaitu [34, 33, 22, 365]. Barulah setelah itu di-encode dengan algoritma\n",
        "    compression Variable-Byte Encoding, dan kemudian diubah ke bytesream.\n",
        "\n",
        "    ASUMSI: postings_list untuk sebuah term MUAT di memori!\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def vb_encode_number(number):\n",
        "        \"\"\"\n",
        "        Encodes a number using Variable-Byte Encoding\n",
        "        Lihat buku teks kita!\n",
        "        \"\"\"\n",
        "        bytes = []\n",
        "        while True:\n",
        "            bytes.insert(0, number % 128) # prepend ke depan\n",
        "            if number < 128:\n",
        "                break\n",
        "            number = number // 128\n",
        "        bytes[-1] += 128 # bit awal pada byte terakhir diganti 1\n",
        "        return array.array('B', bytes).tobytes()\n",
        "\n",
        "    @staticmethod\n",
        "    def vb_encode(list_of_numbers):\n",
        "        \"\"\" \n",
        "        Melakukan encoding (tentunya dengan compression) terhadap\n",
        "        list of numbers, dengan Variable-Byte Encoding\n",
        "        \"\"\"\n",
        "        bytes = []\n",
        "        for number in list_of_numbers:\n",
        "            bytes.append(VBEPostings.vb_encode_number(number))\n",
        "        return b\"\".join(bytes)\n",
        "\n",
        "    @staticmethod\n",
        "    def encode(postings_list):\n",
        "        \"\"\"\n",
        "        Encode postings_list menjadi stream of bytes (dengan Variable-Byte\n",
        "        Encoding). JANGAN LUPA diubah dulu ke gap-based list, sebelum\n",
        "        di-encode dan diubah ke bytearray.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        postings_list: List[int]\n",
        "            List of docIDs (postings)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bytes\n",
        "            bytearray yang merepresentasikan urutan integer di postings_list\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        gap_list = [postings_list[0]] + [postings_list[i+1] - postings_list[i] for i in range(len(postings_list) - 1)]\n",
        "        return VBEPostings.vb_encode(gap_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_tf(tf_list):\n",
        "        \"\"\"\n",
        "        Encode list of term frequencies menjadi stream of bytes\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        tf_list: List[int]\n",
        "            List of term frequencies\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        bytes\n",
        "            bytearray yang merepresentasikan nilai raw TF kemunculan term di setiap\n",
        "            dokumen pada list of postings\n",
        "        \"\"\"\n",
        "        return VBEPostings.vb_encode(tf_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def vb_decode(encoded_bytestream):\n",
        "        \"\"\"\n",
        "        Decoding sebuah bytestream yang sebelumnya di-encode dengan\n",
        "        variable-byte encoding.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        numbers = []\n",
        "        n = 0\n",
        "        for i in range(len(encoded_bytestream)):\n",
        "            if encoded_bytestream[i] < 128:\n",
        "                n = 128 * n + encoded_bytestream[i]\n",
        "            else:\n",
        "                n = 128 * n + (encoded_bytestream[i] - 128)\n",
        "                numbers.append(n)\n",
        "                n = 0\n",
        "        return numbers\n",
        "\n",
        "    @staticmethod\n",
        "    def decode(encoded_postings_list):\n",
        "        \"\"\"\n",
        "        Decodes postings_list dari sebuah stream of bytes. JANGAN LUPA\n",
        "        bytestream yang di-decode dari encoded_postings_list masih berupa\n",
        "        gap-based list.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        encoded_postings_list: bytes\n",
        "            bytearray merepresentasikan encoded postings list sebagai keluaran\n",
        "            dari static method encode di atas.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[int]\n",
        "            list of docIDs yang merupakan hasil decoding dari encoded_postings_list\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        gap_list = VBEPostings.vb_decode(encoded_postings_list)\n",
        "        return [sum(gap_list[:i+1]) for i in range(len(gap_list))]\n",
        "\n",
        "    @staticmethod\n",
        "    def decode_tf(encoded_tf_list):\n",
        "        \"\"\"\n",
        "        Decodes list of term frequencies dari sebuah stream of bytes\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        encoded_tf_list: bytes\n",
        "            bytearray merepresentasikan encoded term frequencies list sebagai keluaran\n",
        "            dari static method encode_tf di atas.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[int]\n",
        "            List of term frequencies yang merupakan hasil decoding dari encoded_tf_list\n",
        "        \"\"\"\n",
        "        return VBEPostings.vb_decode(encoded_tf_list)"
      ],
      "metadata": {
        "id": "KUiflrFyyWh6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##index.py"
      ],
      "metadata": {
        "id": "Y7sjhFMSyg5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "class InvertedIndex:\n",
        "    \"\"\"\n",
        "    Class yang mengimplementasikan bagaimana caranya scan atau membaca secara\n",
        "    efisien Inverted Index yang disimpan di sebuah file; dan juga menyediakan\n",
        "    mekanisme untuk menulis Inverted Index ke file (storage) saat melakukan indexing.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    postings_dict: Dictionary mapping:\n",
        "\n",
        "            termID -> (start_position_in_index_file,\n",
        "                       number_of_postings_in_list,\n",
        "                       length_in_bytes_of_postings_list,\n",
        "                       length_in_bytes_of_tf_list)\n",
        "\n",
        "        postings_dict adalah konsep \"Dictionary\" yang merupakan bagian dari\n",
        "        Inverted Index. postings_dict ini diasumsikan dapat dimuat semuanya\n",
        "        di memori.\n",
        "\n",
        "        Seperti namanya, \"Dictionary\" diimplementasikan sebagai python's Dictionary\n",
        "        yang memetakan term ID (integer) ke 4-tuple:\n",
        "           1. start_position_in_index_file : (dalam satuan bytes) posisi dimana\n",
        "              postings yang bersesuaian berada di file (storage). Kita bisa\n",
        "              menggunakan operasi \"seek\" untuk mencapainya.\n",
        "           2. number_of_postings_in_list : berapa banyak docID yang ada pada\n",
        "              postings (Document Frequency)\n",
        "           3. length_in_bytes_of_postings_list : panjang postings list dalam\n",
        "              satuan byte.\n",
        "           4. length_in_bytes_of_tf_list : panjang list of term frequencies dari\n",
        "              postings list terkait dalam satuan byte\n",
        "\n",
        "    terms: List[int]\n",
        "        List of terms IDs, untuk mengingat urutan terms yang dimasukan ke\n",
        "        dalam Inverted Index.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, index_name, postings_encoding, directory=''):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        index_name (str): Nama yang digunakan untuk menyimpan files yang berisi index\n",
        "        postings_encoding : Lihat di compression.py, kandidatnya adalah StandardPostings,\n",
        "                        GapBasedPostings, dsb.\n",
        "        directory (str): directory dimana file index berada\n",
        "        \"\"\"\n",
        "\n",
        "        self.index_file_path = os.path.join(directory, index_name+'.index')\n",
        "        self.metadata_file_path = os.path.join(directory, index_name+'.dict')\n",
        "\n",
        "        self.postings_encoding = postings_encoding\n",
        "        self.directory = directory\n",
        "\n",
        "        self.postings_dict = {}\n",
        "        self.terms = []             # Untuk keep track urutan term yang dimasukkan ke index\n",
        "        self.doc_length = {}        # key: doc ID (int), value: document length (number of tokens)\n",
        "        self.average_doc_length = 0 # Ini nantinya akan berguna untuk normalisasi Score terhadap panjang\n",
        "                                    # dokumen saat menghitung score dengan TF-IDF atau BM25\n",
        "\n",
        "    def __enter__(self):\n",
        "        \"\"\"\n",
        "        Memuat semua metadata ketika memasuki context.\n",
        "        Metadata:\n",
        "            1. Dictionary ---> postings_dict\n",
        "            2. iterator untuk List yang berisi urutan term yang masuk ke\n",
        "                index saat konstruksi. ---> term_iter\n",
        "            3. doc_length, sebuah python's dictionary yang berisi key = doc id, dan\n",
        "                value berupa banyaknya token dalam dokumen tersebut (panjang dokumen).\n",
        "                Berguna untuk normalisasi panjang saat menggunakan TF-IDF atau BM25\n",
        "                scoring regime; berguna untuk untuk mengetahui nilai N saat hitung IDF,\n",
        "                dimana N adalah banyaknya dokumen di koleksi\n",
        "\n",
        "        Metadata disimpan ke file dengan bantuan library \"pickle\"\n",
        "\n",
        "        Perlu memahani juga special method __enter__(..) pada Python dan juga\n",
        "        konsep Context Manager di Python. Silakan pelajari link berikut:\n",
        "\n",
        "        https://docs.python.org/3/reference/datamodel.html#object.__enter__\n",
        "        \"\"\"\n",
        "        # Membuka index file\n",
        "        self.index_file = open(self.index_file_path, 'rb+')\n",
        "\n",
        "        # Kita muat postings dict dan terms iterator dari file metadata\n",
        "        with open(self.metadata_file_path, 'rb') as f:\n",
        "            self.postings_dict, self.terms, self.doc_length = pickle.load(f)\n",
        "            self.term_iter = self.terms.__iter__()\n",
        "\n",
        "        self.average_doc_length = sum(self.doc_length.values()) / len(self.doc_length)\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exception_type, exception_value, traceback):\n",
        "        \"\"\"Menutup index_file dan menyimpan postings_dict dan terms ketika keluar context.\n",
        "            Selain itu, juga menghitung rata-rata panjang dokumen.\"\"\"\n",
        "        # Menutup index file\n",
        "        self.index_file.close()\n",
        "        # Menyimpan metadata (postings dict dan terms) ke file metadata dengan bantuan pickle\n",
        "        with open(self.metadata_file_path, 'wb') as f:\n",
        "            pickle.dump([self.postings_dict, self.terms, self.doc_length], f)\n",
        "\n",
        "\n",
        "class InvertedIndexReader(InvertedIndex):\n",
        "    \"\"\"\n",
        "    Class yang mengimplementasikan bagaimana caranya scan atau membaca secara\n",
        "    efisien Inverted Index yang disimpan di sebuah file.\n",
        "    \"\"\"\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Kembalikan file pointer ke awal, dan kembalikan pointer iterator\n",
        "        term ke awal\n",
        "        \"\"\"\n",
        "        self.index_file.seek(0)\n",
        "        self.term_iter = self.terms.__iter__() # reset term iterator\n",
        "\n",
        "    def __next__(self): \n",
        "        \"\"\"\n",
        "        Class InvertedIndexReader juga bersifat iterable (mempunyai iterator).\n",
        "        Silakan pelajari:\n",
        "        https://stackoverflow.com/questions/19151/how-to-build-a-basic-iterator\n",
        "\n",
        "        Ketika instance dari kelas InvertedIndexReader ini digunakan\n",
        "        sebagai iterator pada sebuah loop scheme, special method __next__(...)\n",
        "        bertugas untuk mengembalikan pasangan (term, postings_list, tf_list) berikutnya\n",
        "        pada inverted index.\n",
        "\n",
        "        PERHATIAN! method ini harus mengembalikan sebagian kecil data dari\n",
        "        file index yang besar. Mengapa hanya sebagian kecil? karena agar muat\n",
        "        diproses di memori. JANGAN MEMUAT SEMUA INDEX DI MEMORI!\n",
        "        \"\"\"\n",
        "        curr_term = next(self.term_iter)\n",
        "        # pos, number_of_postings, len_in_bytes_of_postings, len_in_bytes_of_tf = self.postings_dict[curr_term]\n",
        "        # postings_list = self.postings_encoding.decode(self.index_file.read(len_in_bytes_of_postings))\n",
        "        # tf_list = self.postings_encoding.decode_tf(self.index_file.read(len_in_bytes_of_tf))\n",
        "        postings_list, tf_list = self.get_postings_list(curr_term)\n",
        "        return (curr_term, postings_list, tf_list)\n",
        "\n",
        "    def get_postings_list(self, term):\n",
        "        \"\"\"\n",
        "        Kembalikan sebuah postings list (list of docIDs) beserta list\n",
        "        of term frequencies terkait untuk sebuah term (disimpan dalam\n",
        "        bentuk tuple (postings_list, tf_list)).\n",
        "\n",
        "        PERHATIAN! method tidak boleh iterasi di keseluruhan index\n",
        "        dari awal hingga akhir. Method ini harus langsung loncat ke posisi\n",
        "        byte tertentu pada file (index file) dimana postings list (dan juga\n",
        "        list of TF) dari term disimpan.\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        start, _, len_in_bytes_of_postings, \\\n",
        "            len_in_bytes_of_tf = self.postings_dict[term]\n",
        "\n",
        "        self.index_file.seek(start)\n",
        "        encoded_postings_list = self.index_file.read(len_in_bytes_of_postings)\n",
        "        encoded_tf_list = self.index_file.read(len_in_bytes_of_tf)\n",
        "        decoded_postings_list = self.postings_encoding.decode(encoded_postings_list)\n",
        "        decoded_tf_list = self.postings_encoding.decode_tf(encoded_tf_list)\n",
        "\n",
        "        return (decoded_postings_list, decoded_tf_list)\n",
        "\n",
        "\n",
        "class InvertedIndexWriter(InvertedIndex):\n",
        "    \"\"\"\n",
        "    Class yang mengimplementasikan bagaimana caranya menulis secara\n",
        "    efisien Inverted Index yang disimpan di sebuah file.\n",
        "    \"\"\"\n",
        "    def __enter__(self):\n",
        "        self.index_file = open(self.index_file_path, 'wb+')\n",
        "        return self\n",
        "\n",
        "    def append(self, term, postings_list, tf_list):\n",
        "        \"\"\"\n",
        "        Menambahkan (append) sebuah term, postings_list, dan juga TF list \n",
        "        yang terasosiasi ke posisi akhir index file.\n",
        "\n",
        "        Method ini melakukan 4 hal:\n",
        "        1. Encode postings_list menggunakan self.postings_encoding (method encode),\n",
        "        2. Encode tf_list menggunakan self.postings_encoding (method encode_tf),\n",
        "        3. Menyimpan metadata dalam bentuk self.terms, self.postings_dict, dan self.doc_length.\n",
        "           Ingat kembali bahwa self.postings_dict memetakan sebuah termID ke\n",
        "           sebuah 4-tuple: - start_position_in_index_file\n",
        "                           - number_of_postings_in_list\n",
        "                           - length_in_bytes_of_postings_list\n",
        "                           - length_in_bytes_of_tf_list\n",
        "        4. Menambahkan (append) bystream dari postings_list yang sudah di-encode dan\n",
        "           tf_list yang sudah di-encode ke posisi akhir index file di harddisk.\n",
        "\n",
        "        Jangan lupa update self.terms dan self.doc_length juga ya!\n",
        "\n",
        "        SEARCH ON YOUR FAVORITE SEARCH ENGINE:\n",
        "        - Anda mungkin mau membaca tentang Python I/O\n",
        "          https://docs.python.org/3/tutorial/inputoutput.html\n",
        "          Di link ini juga bisa kita pelajari bagaimana menambahkan informasi\n",
        "          ke bagian akhir file.\n",
        "        - Beberapa method dari object file yang mungkin berguna seperti seek(...)\n",
        "          dan tell()\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        term:\n",
        "            term atau termID yang merupakan unique identifier dari sebuah term\n",
        "        postings_list: List[Int]\n",
        "            List of docIDs dimana term muncul\n",
        "        tf_list: List[Int]\n",
        "            List of term frequencies\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        encoded_postings_list = self.postings_encoding.encode(postings_list)\n",
        "        encoded_tf = self.postings_encoding.encode_tf(tf_list)\n",
        "\n",
        "        for doc_id, tf in zip(postings_list, tf_list):\n",
        "            if doc_id not in self.doc_length:\n",
        "                self.doc_length[doc_id] = tf\n",
        "            else:\n",
        "                self.doc_length[doc_id] += tf\n",
        "        \n",
        "        self.postings_dict[term] = (self.index_file.tell(),\n",
        "                                    len(postings_list),\n",
        "                                    len(encoded_postings_list),\n",
        "                                    len(encoded_tf))\n",
        "        \n",
        "        self.terms.append(term)\n",
        "\n",
        "        self.index_file.write(encoded_postings_list)\n",
        "        self.index_file.write(encoded_tf)"
      ],
      "metadata": {
        "id": "CeTL5J13yrGL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bsbi.py"
      ],
      "metadata": {
        "id": "YRdtspXSyuHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import contextlib\n",
        "import glob\n",
        "import heapq\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "class BSBIIndex:\n",
        "    \"\"\"\n",
        "    Attributes\n",
        "    ----------\n",
        "    term_id_map(IdMap): Untuk mapping terms ke termIDs\n",
        "    doc_id_map(IdMap): Untuk mapping relative paths dari dokumen (misal,\n",
        "                    /collection/0/gamma.txt) to docIDs\n",
        "    data_dir(str): Path ke data\n",
        "    output_dir(str): Path ke output index files\n",
        "    postings_encoding: Lihat di compression.py, kandidatnya adalah StandardPostings,\n",
        "                    VBEPostings, dsb.\n",
        "    index_name(str): Nama dari file yang berisi inverted index\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, output_dir, postings_encoding, index_name = \"main_index\"):\n",
        "        self.term_id_map = IdMap()\n",
        "        self.doc_id_map = IdMap()\n",
        "        self.data_dir = data_dir\n",
        "        self.output_dir = output_dir\n",
        "        self.index_name = index_name\n",
        "        self.postings_encoding = postings_encoding\n",
        "\n",
        "        # Untuk menyimpan nama-nama file dari semua intermediate inverted index\n",
        "        self.intermediate_indices = []\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Menyimpan doc_id_map and term_id_map ke output directory via pickle\"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, 'terms.dict'), 'wb') as f:\n",
        "            pickle.dump(self.term_id_map, f)\n",
        "        with open(os.path.join(self.output_dir, 'docs.dict'), 'wb') as f:\n",
        "            pickle.dump(self.doc_id_map, f)\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Memuat doc_id_map and term_id_map dari output directory\"\"\"\n",
        "\n",
        "        with open(os.path.join(self.output_dir, 'terms.dict'), 'rb') as f:\n",
        "            self.term_id_map = pickle.load(f)\n",
        "        with open(os.path.join(self.output_dir, 'docs.dict'), 'rb') as f:\n",
        "            self.doc_id_map = pickle.load(f)\n",
        "\n",
        "    def parse_block(self, block_dir_relative):\n",
        "        \"\"\"\n",
        "        Lakukan parsing terhadap text file sehingga menjadi sequence of\n",
        "        <termID, docID> pairs.\n",
        "\n",
        "        Gunakan tools available untuk Stemming Bahasa Inggris\n",
        "\n",
        "        JANGAN LUPA BUANG STOPWORDS!\n",
        "\n",
        "        Untuk \"sentence segmentation\" dan \"tokenization\", bisa menggunakan\n",
        "        regex atau boleh juga menggunakan tools lain yang berbasis machine\n",
        "        learning.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        block_dir_relative : str\n",
        "            Relative Path ke directory yang mengandung text files untuk sebuah block.\n",
        "\n",
        "            CATAT bahwa satu folder di collection dianggap merepresentasikan satu block.\n",
        "            Konsep block di soal tugas ini berbeda dengan konsep block yang terkait\n",
        "            dengan operating systems.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[Tuple[Int, Int]]\n",
        "            Returns all the td_pairs extracted from the block\n",
        "            Mengembalikan semua pasangan <termID, docID> dari sebuah block (dalam hal\n",
        "            ini sebuah sub-direktori di dalam folder collection)\n",
        "\n",
        "        Harus menggunakan self.term_id_map dan self.doc_id_map untuk mendapatkan\n",
        "        termIDs dan docIDs. Dua variable ini harus 'persist' untuk semua pemanggilan\n",
        "        parse_block(...).\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        dir_path = os.path.join(self.data_dir, block_dir_relative)\n",
        "        td_pairs = []\n",
        "\n",
        "        for filename in os.listdir(dir_path):\n",
        "            with open(os.path.join(dir_path, filename), 'r') as f:\n",
        "                string = f.read()\n",
        "                tokens = text_preprocess(string)\n",
        "\n",
        "                doc_id = self.doc_id_map[f.name]\n",
        "                for token in tokens:\n",
        "                    term_id = self.term_id_map[token]\n",
        "                    td_pairs.append((term_id, doc_id))\n",
        "\n",
        "        return td_pairs\n",
        "\n",
        "    def invert_write(self, td_pairs, index):\n",
        "        \"\"\"\n",
        "        Melakukan inversion td_pairs (list of <termID, docID> pairs) dan\n",
        "        menyimpan mereka ke index. Disini diterapkan konsep BSBI dimana \n",
        "        hanya di-mantain satu dictionary besar untuk keseluruhan block.\n",
        "        Namun dalam teknik penyimpanannya digunakan srategi dari SPIMI\n",
        "        yaitu penggunaan struktur data hashtable (dalam Python bisa\n",
        "        berupa Dictionary)\n",
        "\n",
        "        ASUMSI: td_pairs CUKUP di memori\n",
        "\n",
        "        Di Tugas Pemrograman 1, kita hanya menambahkan term dan\n",
        "        juga list of sorted Doc IDs. Sekarang di Tugas Pemrograman 2,\n",
        "        kita juga perlu tambahkan list of TF.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        td_pairs: List[Tuple[Int, Int]]\n",
        "            List of termID-docID pairs\n",
        "        index: InvertedIndexWriter\n",
        "            Inverted index pada disk (file) yang terkait dengan suatu \"block\"\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        term_dict = {}\n",
        "        for term_id, doc_id in td_pairs:\n",
        "            if term_id not in term_dict:\n",
        "                term_dict[term_id] = dict()\n",
        "            if doc_id not in term_dict[term_id]:\n",
        "                term_dict[term_id][doc_id] = 0\n",
        "            term_dict[term_id][doc_id] += 1\n",
        "        for term_id in sorted(term_dict.keys()):\n",
        "            doc_id_freq_pairs = sorted(term_dict[term_id].items())\n",
        "            separated_pairs = list(zip(*doc_id_freq_pairs))\n",
        "            postings_list = list(separated_pairs[0])\n",
        "            tf_list = list(separated_pairs[1])\n",
        "            index.append(term_id, postings_list, tf_list)\n",
        "\n",
        "    def merge(self, indices, merged_index):\n",
        "        \"\"\"\n",
        "        Lakukan merging ke semua intermediate inverted indices menjadi\n",
        "        sebuah single index.\n",
        "\n",
        "        Ini adalah bagian yang melakukan EXTERNAL MERGE SORT\n",
        "\n",
        "        Gunakan fungsi orted_merge_posts_and_tfs(..) di modul util\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        indices: List[InvertedIndexReader]\n",
        "            A list of intermediate InvertedIndexReader objects, masing-masing\n",
        "            merepresentasikan sebuah intermediate inveted index yang iterable\n",
        "            di sebuah block.\n",
        "\n",
        "        merged_index: InvertedIndexWriter\n",
        "            Instance InvertedIndexWriter object yang merupakan hasil merging dari\n",
        "            semua intermediate InvertedIndexWriter objects.\n",
        "        \"\"\"\n",
        "        # kode berikut mengasumsikan minimal ada 1 term\n",
        "        merged_iter = heapq.merge(*indices, key = lambda x: x[0])\n",
        "        curr, postings, tf_list = next(merged_iter) # first item\n",
        "        for t, postings_, tf_list_ in merged_iter: # from the second item\n",
        "            if t == curr:\n",
        "                zip_p_tf = sorted_merge_posts_and_tfs(list(zip(postings, tf_list)), \\\n",
        "                                                      list(zip(postings_, tf_list_)))\n",
        "                postings = [doc_id for (doc_id, _) in zip_p_tf]\n",
        "                tf_list = [tf for (_, tf) in zip_p_tf]\n",
        "            else:\n",
        "                merged_index.append(curr, postings, tf_list)\n",
        "                curr, postings, tf_list = t, postings_, tf_list_\n",
        "        merged_index.append(curr, postings, tf_list)\n",
        "\n",
        "    def retrieve_tfidf(self, query, k = 10):\n",
        "        \"\"\"\n",
        "        Melakukan Ranked Retrieval dengan skema TaaT (Term-at-a-Time).\n",
        "        Method akan mengembalikan top-K retrieval results.\n",
        "\n",
        "        w(t, D) = (1 + log tf(t, D))       jika tf(t, D) > 0\n",
        "                = 0                        jika sebaliknya\n",
        "\n",
        "        w(t, Q) = IDF = log (N / df(t))\n",
        "\n",
        "        Score = untuk setiap term di query, akumulasikan w(t, Q) * w(t, D).\n",
        "                (tidak perlu dinormalisasi dengan panjang dokumen)\n",
        "\n",
        "        catatan: \n",
        "            1. informasi DF(t) ada di dictionary postings_dict pada merged index\n",
        "            2. informasi TF(t, D) ada di tf_li\n",
        "            3. informasi N bisa didapat dari doc_length pada merged index, len(doc_length)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        query: str\n",
        "            Query tokens yang dipisahkan oleh spasi\n",
        "\n",
        "            contoh: Query \"universitas indonesia depok\" artinya ada\n",
        "            tiga terms: universitas, indonesia, dan depok\n",
        "\n",
        "        Result\n",
        "        ------\n",
        "        List[(int, str)]\n",
        "            List of tuple: elemen pertama adalah score similarity, dan yang\n",
        "            kedua adalah nama dokumen.\n",
        "            Daftar Top-K dokumen terurut mengecil BERDASARKAN SKOR.\n",
        "\n",
        "        JANGAN LEMPAR ERROR/EXCEPTION untuk terms yang TIDAK ADA di collection.\n",
        "\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        tokenized = text_preprocess(query)\n",
        "\n",
        "        self.load()\n",
        "        postings_tf_lists = []\n",
        "        n = 0\n",
        "\n",
        "        with InvertedIndexReader(self.index_name, self.postings_encoding, directory=self.output_dir) as inv_reader:\n",
        "            for token in tokenized:\n",
        "                if token not in self.term_id_map:\n",
        "                    continue\n",
        "                postings_tf_lists.append(inv_reader.get_postings_list(self.term_id_map[token]))\n",
        "            n = len(inv_reader.doc_length)\n",
        "\n",
        "        # TaaT\n",
        "        result = {}\n",
        "        for i in range(len(postings_tf_lists)):\n",
        "            df = len(postings_tf_lists[i][0])\n",
        "            wtq = math.log10(n/df)\n",
        "\n",
        "            for j in range(df):\n",
        "                tf = postings_tf_lists[i][1][j]\n",
        "                wtd = (1 + math.log10(tf)) if tf > 0 else 0\n",
        "                score = wtd * wtq\n",
        "                doc_name = self.doc_id_map[postings_tf_lists[i][0][j]]\n",
        "                if doc_name in result:\n",
        "                    result[doc_name] += score\n",
        "                else:\n",
        "                    result[doc_name] = score\n",
        "        \n",
        "        result = result.items()\n",
        "        result = sorted(result, key=lambda x: x[1], reverse=True)[:k]\n",
        "        return result\n",
        "\n",
        "    def retrieve_bm25(self, query, k, k1 = 1.5, b = 0.75):\n",
        "        \"\"\"\n",
        "        Melakukan Ranked Retrieval dengan skema TaaT (Term-at-a-Time).\n",
        "        Method akan mengembalikan top-K retrieval results.\n",
        "\n",
        "        w(t, D) = ((k1 + 1) * tf(t, D)) / ((k1 * ((1-b) + (b*dl/avdl))) + tf(t, D))\n",
        "\n",
        "        w(t, Q) = IDF = log (N / df(t))\n",
        "\n",
        "        Score = untuk setiap term di query, akumulasikan w(t, Q) * w(t, D).\n",
        "                (tidak perlu dinormalisasi dengan panjang dokumen)\n",
        "\n",
        "        catatan: \n",
        "            1. informasi DF(t) ada di dictionary postings_dict pada merged index\n",
        "            2. informasi TF(t, D) ada di tf_li\n",
        "            3. informasi N bisa didapat dari doc_length pada merged index, len(doc_length)\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        query: str\n",
        "            Query tokens yang dipisahkan oleh spasi\n",
        "\n",
        "            contoh: Query \"universitas indonesia depok\" artinya ada\n",
        "            tiga terms: universitas, indonesia, dan depok\n",
        "\n",
        "        Result\n",
        "        ------\n",
        "        List[(int, str)]\n",
        "            List of tuple: elemen pertama adalah score similarity, dan yang\n",
        "            kedua adalah nama dokumen.\n",
        "            Daftar Top-K dokumen terurut mengecil BERDASARKAN SKOR.\n",
        "\n",
        "        JANGAN LEMPAR ERROR/EXCEPTION untuk terms yang TIDAK ADA di collection.\n",
        "\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        tokenized = text_preprocess(query)\n",
        "\n",
        "        self.load()\n",
        "        postings_tf_lists = []\n",
        "        n = 0\n",
        "        result = {}\n",
        "\n",
        "        with InvertedIndexReader(self.index_name, self.postings_encoding, directory=self.output_dir) as inv_reader:\n",
        "            for token in tokenized:\n",
        "                if token not in self.term_id_map:\n",
        "                    continue\n",
        "                postings_tf_lists.append(inv_reader.get_postings_list(self.term_id_map[token]))\n",
        "            n = len(inv_reader.doc_length)\n",
        "\n",
        "            # TaaT\n",
        "            for i in range(len(postings_tf_lists)):\n",
        "                df = len(postings_tf_lists[i][0])\n",
        "                wtq = math.log10(n/df)\n",
        "\n",
        "                for j in range(df):\n",
        "                    tf = postings_tf_lists[i][1][j]\n",
        "                    doc_id = postings_tf_lists[i][0][j]\n",
        "                    dl = inv_reader.doc_length[doc_id]\n",
        "                    avdl = inv_reader.average_doc_length\n",
        "                    wtd = ((k1 + 1) * tf) / ((k1 * ((1-b) + (b*dl/avdl))) + tf)\n",
        "                    score = wtd * wtq\n",
        "                    doc_name = self.doc_id_map[doc_id]\n",
        "                    if doc_name in result:\n",
        "                        result[doc_name] += score\n",
        "                    else:\n",
        "                        result[doc_name] = score\n",
        "        \n",
        "        result = result.items()\n",
        "        result = sorted(result, key=lambda x: x[1], reverse=True)[:k]\n",
        "        return result\n",
        "\n",
        "    def index(self):\n",
        "        \"\"\"\n",
        "        Base indexing code\n",
        "        BAGIAN UTAMA untuk melakukan Indexing dengan skema BSBI (blocked-sort\n",
        "        based indexing)\n",
        "\n",
        "        Method ini scan terhadap semua data di collection, memanggil parse_block\n",
        "        untuk parsing dokumen dan memanggil invert_write yang melakukan inversion\n",
        "        di setiap block dan menyimpannya ke index yang baru.\n",
        "        \"\"\"\n",
        "        # loop untuk setiap sub-directory di dalam folder collection (setiap block)\n",
        "        for block_dir_relative in tqdm(sorted(next(os.walk(self.data_dir))[1])):\n",
        "            td_pairs = self.parse_block(block_dir_relative)\n",
        "            index_id = 'intermediate_index_'+block_dir_relative\n",
        "            self.intermediate_indices.append(index_id)\n",
        "            with InvertedIndexWriter(index_id, self.postings_encoding, directory = self.output_dir) as index:\n",
        "                self.invert_write(td_pairs, index)\n",
        "                td_pairs = None\n",
        "    \n",
        "        self.save()\n",
        "\n",
        "        with InvertedIndexWriter(self.index_name, self.postings_encoding, directory = self.output_dir) as merged_index:\n",
        "            with contextlib.ExitStack() as stack:\n",
        "                indices = [stack.enter_context(InvertedIndexReader(index_id, self.postings_encoding, directory=self.output_dir))\n",
        "                               for index_id in self.intermediate_indices]\n",
        "                self.merge(indices, merged_index)"
      ],
      "metadata": {
        "id": "lz4i22bkyxdU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/IR/index"
      ],
      "metadata": {
        "id": "HeE5Vc6k3N14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffd71ca-ca04-4c84-9e1d-9f6ae97bad5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/IR/index’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BSBI_instance = BSBIIndex(data_dir = '/content/drive/MyDrive/IR/collection', \\\n",
        "                          postings_encoding = VBEPostings, \\\n",
        "                          output_dir = '/content/drive/MyDrive/IR/index')\n",
        "BSBI_instance.index() # memulai indexing!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipahlFD1zm8t",
        "outputId": "c812c699-8613-4235-91e9-3b91cc0261d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [01:42<00:00,  9.36s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagian yang berbeda dari TP 3"
      ],
      "metadata": {
        "id": "1_Oy8U4iMZ6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## experiment.py"
      ],
      "metadata": {
        "id": "TN16ui0D366b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inisialisasi model BioClinicalBERT"
      ],
      "metadata": {
        "id": "qHngsjaQMqd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "9ngsboN_K_fA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3488ca88-bd88-4937-9842-d983aade89f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TFBertModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "bert_model = TFBertModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\", \\\n",
        "                                         output_attentions=True, \\\n",
        "                                         from_pt = True)"
      ],
      "metadata": {
        "id": "6G91vSOvK-C9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "9195664e946541ce835a76b41e03749f",
            "bab7c71287074a56905964c2d22d4fd0",
            "7f9565db30ce4d44b5d9c7cdea207ba7",
            "7e51caef30b94a7ebee48ea8b514a016",
            "ea320908140a4c938536d074dfed15c5",
            "963003d0dc204d129b4c4bdbabde20ac",
            "68cf58e22c144f1f894de6bd11c92763",
            "90228885f4004f8c99e4c8980d149a39",
            "cc237ca4cddf4d2cb612b8b2fd645cae",
            "a97136d016c24137804db90a74514ca4",
            "161e45f53dec437890081f10f4e8cef1",
            "96855ebb653c470bb56df72591c1bdba",
            "5725fe46998b441cb9ba2ed372a975d2",
            "059df2203dd74cdea1e56a2a7495f417",
            "c26fc4ce60cb4fa686b5cb803b001431",
            "241daa8666be4c9e8998ba1880be69a5",
            "5d1950d598244d8b8c408fb026822511",
            "224b980d21b74348ba8f6fe2ba5e9996",
            "8e3bc79398a84c69ac3d26562b324b50",
            "b8824017a2cb40d79e3697624d4ca444",
            "76fbed5ac3804608a9ade331ba6bf3bf",
            "6b7846406af14f41aebd23b3e5e9c85b",
            "2714cb17b48b4599b1518eb1c97aaf96",
            "4890895c72964a07965d94d3745acb3d",
            "11bb15c327a64e9a919b043019641b69",
            "1c37cc7201d54a348c988db6352e878e",
            "9b3d0ee82ca548c9908a02be8d4baf97",
            "1555473c512a4ccf8d78445cc29ee0ed",
            "56328d0cf6ee4e1688ece5b1e9f00c68",
            "c015f74bdf0545f790f93f67d679e65a",
            "5f6fae2a7fbe423594b933a98ae70104",
            "73041d741eb643579b8e9493874f23a0",
            "9d90c5fcaa574d86bb80bb897b2cc82a"
          ]
        },
        "outputId": "88ac3c00-07a4-4cad-e5a5-8b1c4bd86c8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9195664e946541ce835a76b41e03749f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96855ebb653c470bb56df72591c1bdba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2714cb17b48b4599b1518eb1c97aaf96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menambahkan layer classifier dari output BioClinicalBERT"
      ],
      "metadata": {
        "id": "gGUHZEZwM8JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from transformers import TFBertModel\n",
        "from keras.layers import Dropout, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "class MedlineModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_class=3,\n",
        "                 model_name=\"emilyalsentzer/Bio_ClinicalBERT\", dropout_prob=0.1):\n",
        "        super().__init__(name=\"Medline_Model\")\n",
        "        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.dropout = Dropout(dropout_prob)\n",
        "        self.dense_classifier = Dense(num_class,name=\"dense_classifier\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # get pooler output for CLS embedding\n",
        "        trained_bert = self.bert(inputs, **kwargs)\n",
        "        cls_embed = trained_bert.pooler_output\n",
        "        \n",
        "        sequence_output = self.dropout(cls_embed,\n",
        "                                       training=kwargs.get(\"training\", False))\n",
        "        output_logits = self.dense_classifier(sequence_output)\n",
        "\n",
        "        return output_logits\n"
      ],
      "metadata": {
        "id": "TV6uOOm6a60L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MedlineModel()"
      ],
      "metadata": {
        "id": "oMOy99zTbskR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34a9316-e99c-49cb-9a47-7cedb127cd6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model format h5 tidak menyimpan ukuran input, maka itu kita perlu inisialisasi\n",
        "# ukuran input yang sesuai dengan proses train sebelum memprediksi\n",
        "model_shape = tokenizer('dummy', 'text', padding=True, truncation=True, max_length=300, return_tensors='tf')\n",
        "model(model_shape)\n",
        "model.load_weights('/content/drive/MyDrive/IR/model/weight_bioclinicalbert_epoch_11.h5')"
      ],
      "metadata": {
        "id": "n7DyUkFgcVxI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_texts(documents, max_length = None):\n",
        "    return tokenizer(documents, padding='max_length', max_length=max_length,\n",
        "                     truncation=True)"
      ],
      "metadata": {
        "id": "2Nm9k8QgLVer"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_pred(encoded_inputs):\n",
        "    \"\"\"Membuat semua bagian hasil tokenizer menjadi ndarray numpy\"\"\"\n",
        "    ids = np.array(encoded_inputs['input_ids'])\n",
        "    tid = np.array(encoded_inputs['token_type_ids'])\n",
        "    ams = np.array(encoded_inputs['attention_mask'])\n",
        "\n",
        "    return {\"input_ids\": ids, \"token_type_ids\": tid,  \"attention_mask\": ams}"
      ],
      "metadata": {
        "id": "Jl0CpdBIP-0n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ntpath\n",
        "\n",
        "def path_leaf(path):\n",
        "    head, tail = ntpath.split(path)\n",
        "    return tail or ntpath.basename(head)"
      ],
      "metadata": {
        "id": "R5qR8YO158-H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Menyiapkan metrik evaluasi untuk reranking (sama seperti TP3)"
      ],
      "metadata": {
        "id": "Hg12UgVYWehA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "######## >>>>> 3 IR metrics: RBP p = 0.8, DCG, dan AP\n",
        "\n",
        "def rbp(ranking, p = 0.8):\n",
        "  \"\"\" menghitung search effectiveness metric score dengan \n",
        "      Rank Biased Precision (RBP)\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      ranking: List[int]\n",
        "         vektor biner seperti [1, 0, 1, 1, 1, 0]\n",
        "         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n",
        "         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n",
        "                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n",
        "                 di rank-6 tidak relevan\n",
        "        \n",
        "      Returns\n",
        "      -------\n",
        "      Float\n",
        "        score RBP\n",
        "  \"\"\"\n",
        "  score = 0.\n",
        "  for i in range(1, len(ranking) + 1):\n",
        "    pos = i - 1\n",
        "    score += ranking[pos] * (p ** (i - 1))\n",
        "  return (1 - p) * score\n",
        "\n",
        "def dcg(ranking):\n",
        "  \"\"\" menghitung search effectiveness metric score dengan \n",
        "      Discounted Cumulative Gain\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      ranking: List[int]\n",
        "         vektor biner seperti [1, 0, 1, 1, 1, 0]\n",
        "         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n",
        "         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n",
        "                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n",
        "                 di rank-6 tidak relevan\n",
        "        \n",
        "      Returns\n",
        "      -------\n",
        "      Float\n",
        "        score DCG\n",
        "  \"\"\"\n",
        "  # TODO\n",
        "  score = 0\n",
        "  for i in range(len(ranking)):\n",
        "    score += ranking[i]/math.log2(i+2)\n",
        "  return score\n",
        "\n",
        "def ap(ranking):\n",
        "  \"\"\" menghitung search effectiveness metric score dengan \n",
        "      Average Precision\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      ranking: List[int]\n",
        "         vektor biner seperti [1, 0, 1, 1, 1, 0]\n",
        "         gold standard relevansi dari dokumen di rank 1, 2, 3, dst.\n",
        "         Contoh: [1, 0, 1, 1, 1, 0] berarti dokumen di rank-1 relevan,\n",
        "                 di rank-2 tidak relevan, di rank-3,4,5 relevan, dan\n",
        "                 di rank-6 tidak relevan\n",
        "        \n",
        "      Returns\n",
        "      -------\n",
        "      Float\n",
        "        score AP\n",
        "  \"\"\"\n",
        "  # TODO\n",
        "  def prec_k(k):\n",
        "    score = 0\n",
        "    for i in range(k):\n",
        "      score += ranking[i]/(k)\n",
        "    return score\n",
        "    \n",
        "  R = sum(ranking) if sum(ranking) > 0 else 1\n",
        "\n",
        "  score = 0\n",
        "  for k in range(len(ranking)):\n",
        "    score += (prec_k(k+1)*ranking[k])/R\n",
        "  return score\n",
        "\n",
        "######## >>>>> memuat qrels\n",
        "\n",
        "def load_qrels(qrel_file = \"qrels.txt\", max_q_id = 30, max_doc_id = 1033):\n",
        "  \"\"\" memuat query relevance judgment (qrels) \n",
        "      dalam format dictionary of dictionary\n",
        "      qrels[query id][document id]\n",
        "\n",
        "      dimana, misal, qrels[\"Q3\"][12] = 1 artinya Doc 12\n",
        "      relevan dengan Q3; dan qrels[\"Q3\"][10] = 0 artinya\n",
        "      Doc 10 tidak relevan dengan Q3.\n",
        "\n",
        "  \"\"\"\n",
        "  qrels = {\"Q\" + str(i) : {i:0 for i in range(1, max_doc_id + 1)} \\\n",
        "                 for i in range(1, max_q_id + 1)}\n",
        "  with open(qrel_file) as file:\n",
        "    for line in file:\n",
        "      parts = line.strip().split()\n",
        "      qid = parts[0]\n",
        "      did = int(parts[1])\n",
        "      qrels[qid][did] = 1\n",
        "  return qrels"
      ],
      "metadata": {
        "id": "XMWtMmQ736bY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metode evaluasi yang berbeda dari TP 3"
      ],
      "metadata": {
        "id": "cFZyrCeVWpy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######## >>>>> EVALUASI !\n",
        "from functools import reduce\n",
        "\n",
        "def eval(qrels, query_file = \"queries.txt\", k = 1000, reranking = True,\n",
        "         MAX_LENGTH = 300, bm25 = True):\n",
        "  \"\"\" \n",
        "    loop ke semua 30 query, hitung score di setiap query,\n",
        "    lalu hitung MEAN SCORE over those 30 queries.\n",
        "    untuk setiap query, kembalikan top-k documents\n",
        "  \"\"\"\n",
        "  BSBI_instance = BSBIIndex(data_dir = '/content/drive/MyDrive/IR/collection', \\\n",
        "                          postings_encoding = VBEPostings, \\\n",
        "                          output_dir = '/content/drive/MyDrive/IR/index')\n",
        "\n",
        "  dict_qd = dict()\n",
        "\n",
        "  dict_index = dict()\n",
        "\n",
        "  detokenizer = TreebankWordDetokenizer()\n",
        "\n",
        "  with open(query_file) as file:\n",
        "    rbp_scores = []\n",
        "    dcg_scores = []\n",
        "    ap_scores = []\n",
        "    for qline in file:\n",
        "      parts = qline.strip().split()\n",
        "      qid = parts[0]\n",
        "      query = \" \".join(parts[1:])\n",
        "      qd_pred = []\n",
        "      doc_idx = []\n",
        "\n",
        "      # HATI-HATI, doc id saat indexing bisa jadi berbeda dengan doc id\n",
        "      # yang tertera di qrels\n",
        "      ranking = []\n",
        "\n",
        "      if bm25:\n",
        "        retrieved = BSBI_instance.retrieve_bm25(query, k = k, k1 = 2, b = 0.75)\n",
        "      else:\n",
        "        retrieved = BSBI_instance.retrieve_tfidf(query, k = k)\n",
        "      for (doc, score) in retrieved:\n",
        "          did = int(re.search(r'(.*)\\.txt', path_leaf(doc)).group(1))\n",
        "          doc_idx.append(did)\n",
        "          if reranking:\n",
        "            # simpan konten dokumen untuk bahan prediksi model\n",
        "            with open(doc, encoding=\"utf-8\") as collection_file:\n",
        "              tokenized_doc = word_tokenize(collection_file.read())\n",
        "              str_doc = detokenizer.detokenize(tokenized_doc)\n",
        "              qd_pred.append((query, str_doc))\n",
        "          ranking.append(qrels[qid][did])\n",
        "      dict_qd[qid] = qd_pred\n",
        "      dict_index[qid] = doc_idx\n",
        "\n",
        "      rbp_scores.append(rbp(ranking))\n",
        "      dcg_scores.append(dcg(ranking))\n",
        "      ap_scores.append(ap(ranking))\n",
        "  print(f\"Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = {k}) terhadap 30 queries\")\n",
        "  print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n",
        "  print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n",
        "  print(\"AP score  =\", sum(ap_scores) / len(ap_scores))\n",
        "  \n",
        "\n",
        "  if reranking:\n",
        "    rbp_scores = []\n",
        "    dcg_scores = []\n",
        "    ap_scores = []\n",
        "    for qid in dict_qd.keys():\n",
        "      qd_pred = dict_qd[qid]\n",
        "      doc_idx = dict_index[qid]\n",
        "\n",
        "      encoded_inputs_pred = encode_texts(qd_pred, max_length = MAX_LENGTH)\n",
        "      x = create_pred(encoded_inputs_pred)\n",
        "\n",
        "      # Hasil prediksi adalah 2d array berukuran banyak_data row\n",
        "      # dan banyak_kelas kolom. Karena modelnya dilatih untuk menghasilkan\n",
        "      # tiga kelas, maka nanti akan ada tiga kolom\n",
        "      predicted = model.predict(x)\n",
        "\n",
        "      # Skor cukup dihitung dengan ambil index yang paling besar\n",
        "      # elemennya (cari argmax).\n",
        "      # misal pred = [2.33 9.232 1.2], maka score-nya adalah 1\n",
        "      scores = [np.argmax(pred) for pred in predicted]\n",
        "\n",
        "      doc_id_scores = [x for x in zip([did for did in doc_idx], scores)]\n",
        "      sorted_scores = sorted(doc_id_scores, key = lambda tup: tup[1], reverse = True)\n",
        "\n",
        "      ranking = [qrels[qid][did] for (did, _) in sorted_scores]\n",
        "\n",
        "      rbp_scores.append(rbp(ranking))\n",
        "      dcg_scores.append(dcg(ranking))\n",
        "      ap_scores.append(ap(ranking))\n",
        "\n",
        "    print(\"Hasil evaluasi reranking\")\n",
        "    print(\"RBP score =\", sum(rbp_scores) / len(rbp_scores))\n",
        "    print(\"DCG score =\", sum(dcg_scores) / len(dcg_scores))\n",
        "    print(\"AP score  =\", sum(ap_scores) / len(ap_scores))"
      ],
      "metadata": {
        "id": "nr2nLMlRLI9Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hasil evaluasi"
      ],
      "metadata": {
        "id": "t1B1sCqxXk8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 5 documents"
      ],
      "metadata": {
        "id": "cFCsiitoZAbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k=5)"
      ],
      "metadata": {
        "id": "vn5Fn8b74ekt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a68319-dedd-401a-d13f-ad8f32b9ad12"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 5) terhadap 30 queries\n",
            "RBP score = 0.3575786666666666\n",
            "DCG score = 1.583826249345555\n",
            "AP score  = 0.6806944444444445\n",
            "1/1 [==============================] - 0s 187ms/step\n",
            "1/1 [==============================] - 0s 157ms/step\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.3575786666666666\n",
            "DCG score = 1.583826249345555\n",
            "AP score  = 0.6806944444444445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 10 documents"
      ],
      "metadata": {
        "id": "458f4lJyZEh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8425c18f-145d-49a3-8093-a949f24700d9",
        "id": "znRhXViJ-x4Z"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 10) terhadap 30 queries\n",
            "RBP score = 0.4213984972800001\n",
            "DCG score = 2.0179717759990576\n",
            "AP score  = 0.6431168430335098\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 229ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.4213984972800001\n",
            "DCG score = 2.0179717759990576\n",
            "AP score  = 0.6431168430335098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 50 documents"
      ],
      "metadata": {
        "id": "kBamphPjZIPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac388f8-dc5a-4365-906d-293210d67720",
        "id": "eTuMX4GL4lh3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 50) terhadap 30 queries\n",
            "RBP score = 0.4416710196150325\n",
            "DCG score = 2.8012324128494015\n",
            "AP score  = 0.5162565797421899\n",
            "2/2 [==============================] - 1s 391ms/step\n",
            "2/2 [==============================] - 1s 424ms/step\n",
            "2/2 [==============================] - 1s 216ms/step\n",
            "2/2 [==============================] - 1s 421ms/step\n",
            "2/2 [==============================] - 1s 413ms/step\n",
            "2/2 [==============================] - 1s 416ms/step\n",
            "2/2 [==============================] - 1s 413ms/step\n",
            "2/2 [==============================] - 1s 414ms/step\n",
            "2/2 [==============================] - 1s 407ms/step\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "2/2 [==============================] - 1s 416ms/step\n",
            "2/2 [==============================] - 1s 409ms/step\n",
            "2/2 [==============================] - 1s 301ms/step\n",
            "2/2 [==============================] - 1s 408ms/step\n",
            "2/2 [==============================] - 1s 412ms/step\n",
            "2/2 [==============================] - 1s 412ms/step\n",
            "2/2 [==============================] - 1s 402ms/step\n",
            "2/2 [==============================] - 1s 275ms/step\n",
            "2/2 [==============================] - 1s 422ms/step\n",
            "2/2 [==============================] - 1s 404ms/step\n",
            "2/2 [==============================] - 1s 407ms/step\n",
            "2/2 [==============================] - 1s 404ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "2/2 [==============================] - 1s 398ms/step\n",
            "2/2 [==============================] - 1s 407ms/step\n",
            "2/2 [==============================] - 1s 399ms/step\n",
            "2/2 [==============================] - 1s 406ms/step\n",
            "2/2 [==============================] - 1s 398ms/step\n",
            "2/2 [==============================] - 1s 395ms/step\n",
            "2/2 [==============================] - 1s 395ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.4416710196150325\n",
            "DCG score = 2.8012324128494015\n",
            "AP score  = 0.5162565797421899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 100 documents"
      ],
      "metadata": {
        "id": "TqV5pUueZK-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e97868b-63d8-4aae-eec6-1f7f1bd00dbf",
        "id": "S8tznLBtY4aL"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 100) terhadap 30 queries\n",
            "RBP score = 0.44167130187927167\n",
            "DCG score = 2.963526452253798\n",
            "AP score  = 0.4824332968670388\n",
            "2/2 [==============================] - 1s 431ms/step\n",
            "4/4 [==============================] - 2s 474ms/step\n",
            "2/2 [==============================] - 1s 207ms/step\n",
            "2/2 [==============================] - 1s 626ms/step\n",
            "3/3 [==============================] - 2s 600ms/step\n",
            "3/3 [==============================] - 1s 381ms/step\n",
            "4/4 [==============================] - 2s 481ms/step\n",
            "4/4 [==============================] - 2s 480ms/step\n",
            "4/4 [==============================] - 2s 485ms/step\n",
            "1/1 [==============================] - 0s 400ms/step\n",
            "3/3 [==============================] - 2s 545ms/step\n",
            "3/3 [==============================] - 2s 628ms/step\n",
            "2/2 [==============================] - 1s 308ms/step\n",
            "4/4 [==============================] - 2s 498ms/step\n",
            "4/4 [==============================] - 2s 501ms/step\n",
            "4/4 [==============================] - 2s 497ms/step\n",
            "4/4 [==============================] - 2s 497ms/step\n",
            "2/2 [==============================] - 1s 289ms/step\n",
            "3/3 [==============================] - 2s 563ms/step\n",
            "4/4 [==============================] - 2s 491ms/step\n",
            "2/2 [==============================] - 1s 694ms/step\n",
            "4/4 [==============================] - 2s 488ms/step\n",
            "1/1 [==============================] - 0s 264ms/step\n",
            "4/4 [==============================] - 2s 487ms/step\n",
            "4/4 [==============================] - 2s 487ms/step\n",
            "4/4 [==============================] - 2s 487ms/step\n",
            "4/4 [==============================] - 2s 486ms/step\n",
            "4/4 [==============================] - 2s 487ms/step\n",
            "4/4 [==============================] - 2s 485ms/step\n",
            "4/4 [==============================] - 2s 483ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.44167130187927167\n",
            "DCG score = 2.963526452253798\n",
            "AP score  = 0.4824332968670388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 500 documents"
      ],
      "metadata": {
        "id": "3JzXVJPXZM0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7240d1-ec48-4d58-a984-541f2253681e",
        "id": "S6-Bs2gBY9fw"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 500) terhadap 30 queries\n",
            "RBP score = 0.4416713018796457\n",
            "DCG score = 2.991795411969586\n",
            "AP score  = 0.4769026681312379\n",
            "2/2 [==============================] - 1s 434ms/step\n",
            "4/4 [==============================] - 2s 568ms/step\n",
            "2/2 [==============================] - 1s 208ms/step\n",
            "2/2 [==============================] - 1s 631ms/step\n",
            "3/3 [==============================] - 2s 602ms/step\n",
            "3/3 [==============================] - 1s 385ms/step\n",
            "5/5 [==============================] - 3s 627ms/step\n",
            "5/5 [==============================] - 3s 583ms/step\n",
            "4/4 [==============================] - 2s 517ms/step\n",
            "1/1 [==============================] - 0s 402ms/step\n",
            "3/3 [==============================] - 2s 551ms/step\n",
            "3/3 [==============================] - 2s 635ms/step\n",
            "2/2 [==============================] - 1s 311ms/step\n",
            "5/5 [==============================] - 3s 590ms/step\n",
            "4/4 [==============================] - 2s 532ms/step\n",
            "4/4 [==============================] - 3s 642ms/step\n",
            "7/7 [==============================] - 5s 654ms/step\n",
            "2/2 [==============================] - 1s 281ms/step\n",
            "3/3 [==============================] - 2s 557ms/step\n",
            "6/6 [==============================] - 4s 650ms/step\n",
            "2/2 [==============================] - 1s 685ms/step\n",
            "5/5 [==============================] - 3s 630ms/step\n",
            "1/1 [==============================] - 0s 324ms/step\n",
            "5/5 [==============================] - 3s 631ms/step\n",
            "5/5 [==============================] - 3s 591ms/step\n",
            "4/4 [==============================] - 3s 621ms/step\n",
            "6/6 [==============================] - 4s 612ms/step\n",
            "4/4 [==============================] - 2s 575ms/step\n",
            "9/9 [==============================] - 6s 617ms/step\n",
            "5/5 [==============================] - 3s 507ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.4416713018796457\n",
            "DCG score = 2.991795411969586\n",
            "AP score  = 0.4769026681312379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Top 1000 documents"
      ],
      "metadata": {
        "id": "p9nUk_irZPIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qrels = load_qrels(qrel_file='/content/drive/MyDrive/IR/qrels.txt')\n",
        "assert qrels[\"Q1\"][166] == 1, \"qrels salah\"\n",
        "assert qrels[\"Q1\"][300] == 0, \"qrels salah\"\n",
        "\n",
        "eval(qrels, query_file='/content/drive/MyDrive/IR/queries.txt', k = 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79424dc6-d07a-48cf-d61b-2197545d9d18",
        "id": "Xe1vjgpLY-Z8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil evaluasi BM25 (k1 = 2, b = 0.75, k = 1000) terhadap 30 queries\n",
            "RBP score = 0.4416713018796457\n",
            "DCG score = 2.991795411969586\n",
            "AP score  = 0.4769026681312379\n",
            "2/2 [==============================] - 1s 433ms/step\n",
            "4/4 [==============================] - 2s 575ms/step\n",
            "2/2 [==============================] - 1s 214ms/step\n",
            "2/2 [==============================] - 1s 646ms/step\n",
            "3/3 [==============================] - 2s 610ms/step\n",
            "3/3 [==============================] - 1s 386ms/step\n",
            "5/5 [==============================] - 3s 641ms/step\n",
            "5/5 [==============================] - 3s 593ms/step\n",
            "4/4 [==============================] - 2s 528ms/step\n",
            "1/1 [==============================] - 0s 407ms/step\n",
            "3/3 [==============================] - 2s 564ms/step\n",
            "3/3 [==============================] - 2s 650ms/step\n",
            "2/2 [==============================] - 1s 326ms/step\n",
            "5/5 [==============================] - 3s 596ms/step\n",
            "4/4 [==============================] - 2s 530ms/step\n",
            "4/4 [==============================] - 3s 643ms/step\n",
            "7/7 [==============================] - 5s 650ms/step\n",
            "2/2 [==============================] - 1s 277ms/step\n",
            "3/3 [==============================] - 2s 549ms/step\n",
            "6/6 [==============================] - 4s 645ms/step\n",
            "2/2 [==============================] - 1s 677ms/step\n",
            "5/5 [==============================] - 3s 622ms/step\n",
            "1/1 [==============================] - 0s 325ms/step\n",
            "5/5 [==============================] - 3s 628ms/step\n",
            "5/5 [==============================] - 3s 586ms/step\n",
            "4/4 [==============================] - 3s 617ms/step\n",
            "6/6 [==============================] - 4s 608ms/step\n",
            "4/4 [==============================] - 2s 569ms/step\n",
            "9/9 [==============================] - 6s 619ms/step\n",
            "5/5 [==============================] - 3s 514ms/step\n",
            "Hasil evaluasi reranking\n",
            "RBP score = 0.4416713018796457\n",
            "DCG score = 2.991795411969586\n",
            "AP score  = 0.4769026681312379\n"
          ]
        }
      ]
    }
  ]
}